<!DOCTYPE html>
<html lang="zh-CN" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>GPU C/R 论文阅读 Just-In-Time Checkpointing Low Cost Error Recovery from Deep Learning Training Failures | Sharlayan</title>
    <meta name="description" content="EuroSys24 微软 GPU 新作，终于不像读到 Singularity 时那么迷茫了">
    <link rel="preload stylesheet" href="/assets/style.3ef9b918.css" as="style">
    <link rel="modulepreload" href="/assets/chunks/VPAlgoliaSearchBox.7487e039.js">
    <link rel="modulepreload" href="/assets/app.4f98c8bd.js">
    <link rel="modulepreload" href="/assets/zh_blogs_20240903_index.md.eb8dd773.lean.js">
    
    <script src="https://cdn.jsdelivr.net/gh/stevenjoezhang/live2d-widget@latest/autoload.js"></script>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/4.0.0/github-markdown.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdn.staticfile.org/ionicons/2.0.1/css/ionicons.min.css">
  <link rel="icon" type="image/png" href="/logo.png">
  <meta name="author" content="Peihao Yang">
  <meta property="og:title" content="Home">
  <meta property="og:description" content="Home of Peihao Yang">
  <script id="check-dark-light">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
  </head>
  <body>
    <div id="app"><!--[--><div class="Layout" data-v-b617430f><!--[--><!--]--><!--[--><span tabindex="-1" data-v-d4120332></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-d4120332> Skip to content </a><!--]--><!----><header class="VPNav no-sidebar" data-v-b617430f data-v-aa1cde23><div class="VPNavBar" data-v-aa1cde23 data-v-cbdd8588><div class="container" data-v-cbdd8588><div class="title" data-v-cbdd8588><div class="VPNavBarTitle" data-v-cbdd8588 data-v-730d6dd1><a class="title" href="/zh/" data-v-730d6dd1><!--[--><!--]--><!--[--><img class="VPImage logo" src="/assets/logo.png" alt data-v-0f13a436><!--]--><!----><!--[--><!--]--></a></div></div><div class="content" data-v-cbdd8588><div class="curtain" data-v-cbdd8588></div><!--[--><!--]--><div class="VPNavBarSearch search" data-v-cbdd8588 style="--699c4559:&#39;Meta&#39;;"><div id="docsearch"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg class="DocSearch-Search-Icon" width="20" height="20" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-cbdd8588 data-v-2d3a777e><span id="main-nav-aria-label" class="visually-hidden" data-v-2d3a777e>Main Navigation</span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/zh/" data-v-2d3a777e data-v-f559a019 data-v-1a0f9836><!--[-->🏡主页<!--]--><!----></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/zh/about-me/" data-v-2d3a777e data-v-f559a019 data-v-1a0f9836><!--[-->🦹‍♂️关于我<!--]--><!----></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-2d3a777e data-v-fc33d832><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-fc33d832><span class="text" data-v-fc33d832><!----> 📓博客 <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="text-icon" data-v-fc33d832><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span></button><div class="menu" data-v-fc33d832><div class="VPMenu" data-v-fc33d832 data-v-ecf4e7d9><div class="items" data-v-ecf4e7d9><!--[--><!--[--><div class="VPMenuLink" data-v-ecf4e7d9 data-v-c7da634f><a class="VPLink link" href="/zh/blogs/" data-v-c7da634f data-v-1a0f9836><!--[-->📃所有博客<!--]--><!----></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-ecf4e7d9 data-v-c7da634f><a class="VPLink link" href="/zh/blogs/tags/" data-v-c7da634f data-v-1a0f9836><!--[-->🔖标签分类<!--]--><!----></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="https://forsworns.github.io/feed.xml" target="_blank" rel="noreferrer" data-v-2d3a777e data-v-f559a019 data-v-1a0f9836><!--[-->🔥RSS<!--]--><!----></a><!--]--><!--]--></nav><div class="VPFlyout VPNavBarTranslations translations" data-v-cbdd8588 data-v-7cdc304e data-v-fc33d832><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-fc33d832><span class="text" data-v-fc33d832><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="option-icon" data-v-fc33d832><path d="M0 0h24v24H0z" fill="none"></path><path d=" M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z " class="css-c4d79v"></path></svg>  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="text-icon" data-v-fc33d832><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span></button><div class="menu" data-v-fc33d832><div class="VPMenu" data-v-fc33d832 data-v-ecf4e7d9><!----><!--[--><!--[--><div class="items" data-v-7cdc304e><p class="title" data-v-7cdc304e>中文</p><!--[--><div class="VPMenuLink" data-v-7cdc304e data-v-c7da634f><a class="VPLink link" href="/" data-v-c7da634f data-v-1a0f9836><!--[-->English<!--]--><!----></a></div><!--]--></div><!--]--><!--]--></div></div></div><div class="VPNavBarAppearance appearance" data-v-cbdd8588 data-v-7f24c201><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" aria-label="toggle dark mode" aria-checked="false" data-v-7f24c201 data-v-2b897f09 data-v-ab7cdc04><span class="check" data-v-ab7cdc04><span class="icon" data-v-ab7cdc04><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="sun" data-v-2b897f09><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="moon" data-v-2b897f09><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-cbdd8588 data-v-a5afa74d data-v-80c99471><!--[--><a class="VPSocialLink" href="https://github.com/forsworns/blog-vitepress" target="_blank" rel="noopener" data-v-80c99471 data-v-51b6609b><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg></a><a class="VPSocialLink" href="mailto:peihao.young@gmail.com" target="_blank" rel="noopener" data-v-80c99471 data-v-51b6609b><svg role="img" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" width="20">
            <path d="M874.666667 375.189333V746.666667a64 64 0 0 1-64 64H213.333333a64 64 0 0 1-64-64V375.189333l266.090667 225.6a149.333333 149.333333 0 0 0 193.152 0L874.666667 375.189333zM810.666667 213.333333a64.789333 64.789333 0 0 1 22.826666 4.181334 63.616 63.616 0 0 1 26.794667 19.413333 64.32 64.32 0 0 1 9.344 15.466667c2.773333 6.570667 4.48 13.696 4.906667 21.184L874.666667 277.333333v21.333334L553.536 572.586667a64 64 0 0 1-79.893333 2.538666l-3.178667-2.56L149.333333 298.666667v-21.333334a63.786667 63.786667 0 0 1 35.136-57.130666A63.872 63.872 0 0 1 213.333333 213.333333h597.333334z" ></path>
            </svg></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-cbdd8588 data-v-e459e5dc data-v-fc33d832><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-fc33d832><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="icon" data-v-fc33d832><circle cx="12" cy="12" r="2"></circle><circle cx="19" cy="12" r="2"></circle><circle cx="5" cy="12" r="2"></circle></svg></button><div class="menu" data-v-fc33d832><div class="VPMenu" data-v-fc33d832 data-v-ecf4e7d9><!----><!--[--><!--[--><div class="group" data-v-e459e5dc><p class="trans-title" data-v-e459e5dc>中文</p><!--[--><div class="VPMenuLink" data-v-e459e5dc data-v-c7da634f><a class="VPLink link" href="/" data-v-c7da634f data-v-1a0f9836><!--[-->English<!--]--><!----></a></div><!--]--></div><div class="group" data-v-e459e5dc><div class="item appearance" data-v-e459e5dc><p class="label" data-v-e459e5dc>Appearance</p><div class="appearance-action" data-v-e459e5dc><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" aria-label="toggle dark mode" aria-checked="false" data-v-e459e5dc data-v-2b897f09 data-v-ab7cdc04><span class="check" data-v-ab7cdc04><span class="icon" data-v-ab7cdc04><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="sun" data-v-2b897f09><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="moon" data-v-2b897f09><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div></div></div><div class="group" data-v-e459e5dc><div class="item social-links" data-v-e459e5dc><div class="VPSocialLinks social-links-list" data-v-e459e5dc data-v-80c99471><!--[--><a class="VPSocialLink" href="https://github.com/forsworns/blog-vitepress" target="_blank" rel="noopener" data-v-80c99471 data-v-51b6609b><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg></a><a class="VPSocialLink" href="mailto:peihao.young@gmail.com" target="_blank" rel="noopener" data-v-80c99471 data-v-51b6609b><svg role="img" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" width="20">
            <path d="M874.666667 375.189333V746.666667a64 64 0 0 1-64 64H213.333333a64 64 0 0 1-64-64V375.189333l266.090667 225.6a149.333333 149.333333 0 0 0 193.152 0L874.666667 375.189333zM810.666667 213.333333a64.789333 64.789333 0 0 1 22.826666 4.181334 63.616 63.616 0 0 1 26.794667 19.413333 64.32 64.32 0 0 1 9.344 15.466667c2.773333 6.570667 4.48 13.696 4.906667 21.184L874.666667 277.333333v21.333334L553.536 572.586667a64 64 0 0 1-79.893333 2.538666l-3.178667-2.56L149.333333 298.666667v-21.333334a63.786667 63.786667 0 0 1 35.136-57.130666A63.872 63.872 0 0 1 213.333333 213.333333h597.333334z" ></path>
            </svg></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-cbdd8588 data-v-d6834c14><span class="container" data-v-d6834c14><span class="top" data-v-d6834c14></span><span class="middle" data-v-d6834c14></span><span class="bottom" data-v-d6834c14></span></span></button></div></div></div><!----></header><!----><!----><div class="VPContent" id="VPContent" data-v-b617430f data-v-f32377af><div class="VPDoc has-aside" data-v-f32377af data-v-1e970af1><div class="container" data-v-1e970af1><div class="aside" data-v-1e970af1><div class="aside-curtain" data-v-1e970af1></div><div class="aside-container" data-v-1e970af1><div class="aside-content" data-v-1e970af1><div class="VPDocAside" data-v-1e970af1 data-v-b1723386><!--[--><!--]--><!--[--><!--]--><div class="VPDocAsideOutline" data-v-b1723386 data-v-0980ba1d><div class="content" data-v-0980ba1d><div class="outline-marker" data-v-0980ba1d></div><div class="outline-title" data-v-0980ba1d>On this page</div><nav aria-labelledby="doc-outline-aria-label" data-v-0980ba1d><span class="visually-hidden" id="doc-outline-aria-label" data-v-0980ba1d> Table of Contents for current page </span><ul class="root" data-v-0980ba1d data-v-6f4caaf4><!--[--><!--]--></ul></nav></div></div><!--[--><!--]--><div class="spacer" data-v-b1723386></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-1e970af1><div class="content-container" data-v-1e970af1><!--[--><!--]--><main class="main" data-v-1e970af1><div style="position:relative;" class="vp-doc _zh_blogs_20240903_index" data-v-1e970af1><div><nav class="table-of-contents"><ul><li><a href="#摘要">摘要</a></li><li><a href="#_1-引言">1. 引言</a><ul><li><a href="#jit-checkpointing">JIT Checkpointing</a></li></ul></li><li><a href="#_2-关键技术">2. 关键技术</a><ul><li><a href="#具备领域知识的-api-拦截">具备领域知识的 API 拦截</a></li></ul></li><li><a href="#_3-侵入用户代码的-jit-机制">3. 侵入用户代码的 JIT 机制</a><ul><li><a href="#检测通信故障">检测通信故障</a></li><li><a href="#存储-gpu-状态">存储 GPU 状态</a></li><li><a href="#组装正确的-checkpoint">组装正确的 checkpoint</a></li></ul></li><li><a href="#_4-用户无感的-jit-机制">4. 用户无感的 JIT 机制</a><ul><li><a href="#正常状态下的处理">正常状态下的处理</a></li><li><a href="#对于可恢复的错误">对于可恢复的错误</a></li><li><a href="#对于不可恢复的错误">对于不可恢复的错误</a></li></ul></li></ul></nav><p>今天读到了 EuroSys24 的微软论文《Just-In-Time Checkpointing: Low Cost Error Recovery from Deep Learning Training Failures》，做模型训练快速 checkpoint/restore 的。之前一直没看到这篇文章，有点可惜。</p><p>我博客简介里面说的 <a href="https://www.microsoft.com/en-us/research/publication/singularity-planet-scale-preemptive-and-elastic-scheduling-of-ai-workloads/?msockid=12fa3053da4366e502b82236db4b672f" target="_blank" rel="noreferrer">Singularity</a> 是 2022 年微软另一篇 GPU 虚拟化的论文 《Singularity: Planet-Scale, Preemptive and Elastic Scheduling of AI Workloads》（如果大佬您接受俺做的 CUDA 劫持算 GPU 虚拟化的话）。</p><p>最近让我感到类似 Singularity 的冲击的 GPU C/R 相关的论文有两篇：一篇是 SC23 的 workshop 文章《Checkpoint/Restart for CUDA Kernels》；另一篇是 SJTU IPADS 的 《PARALLELGPUOS: A Concurrent OS-level GPU Checkpoint and Restore System using Validated Speculation》。</p><p>闲言少叙，让我们一起走近今天这篇文章，我只会读到第四章完，也就是架构设计结束。第五章是一些数值分析，没有看了。再后面的实验章节我是日常不看的。括号内是一些个人的补充或者想法。</p><h2 id="摘要" tabindex="-1">摘要 <a class="header-anchor" href="#摘要" aria-hidden="true">#</a></h2><p>这篇文章的主要创新点在于，为大规模分布式训练，设计了一种故障后的即时（JIT）的快照恢复机制，仅需要重放少量训练中的 minibatch 即可恢复。而不是常见的：定期对参数做 checkpoint，在出错后所有节点全部回退到上一个 checkpoint。</p><p>这种 JIT 的机制，减少了故障恢复耗时，也就缩短了模型训练的周期，提升了系统资源整体的利用率。因为在生产环境下，通信、掉卡等故障实际上发生的概率很高，特别是对于现在的大规模分布式训练，集群的规模增大，故障的频率也就随之升高。定期做 checkpoint，哪怕是异步的 checkpoint，也会挤占 CPU、带宽等资源，而且这个频率要结合 MTBF、模型规模往往是经验值，难以优化。</p><p>这篇文章的第三章讲了怎么在用户的训练代码中调用他们的 JIT checkpoint 机制；第四章讲了怎么透明地应用 JIT checkpoint，从而避免修改用户代码，显得第三章内容有点鸡肋。</p><h2 id="_1-引言" tabindex="-1">1. 引言 <a class="header-anchor" href="#_1-引言" aria-hidden="true">#</a></h2><p>大模型训练耗时往往在数周到数月，GPU 节点间通过 NVLink、Infiniband 等高速互联技术连接，系统复杂度很高。这种高复杂度系统下的不可恢复的硬件错误、网络拥塞、驱动故障频发，带来了巨大的资源浪费。这是因为训练是同步的，单 GPU 节点的问题需要整个集群停下来，进行故障恢复。</p><p>大模型的训练基于大量的 minibatch 训练样本，在神经网络上进行前向、反向传播、借助 optimizer 调整模型参数。在数据并行范式下，每次 minibatch 迭代，各个节点使用不同的样本，计算梯度，集合通信全局做平均并广播结果到各个节点。其他并行方式类似，也有这样的基于 minibatch 划分的同步点。</p><p>常规的 checkpoint 机制下，不仅浪费了大量的 CPU 侧资源，GPU 资源实际上也被浪费了（这里指的不仅是空载导致的资源浪费）。<strong>因为每次恢复都是从上一个检查点开始，假设训练过程中出错的点是随机的，那么平均下来，每次故障，所有的 GPU 都会重新执行 checkpoint interval 一半的计算。这部分计算是无意义的，因为出错前，这些数据已经被计算过了。</strong></p><p>作者观察到，训练过程中，大部分故障都是单 GPU 卡故障或者网络的故障，重启任务即可解决，CPU 侧或者是多节点故障比较少。至于 MTBF，普遍是在 24 小时内。OPT 175B 在 992 个 GPU 上训练了两个月，遇到了 100 余次故障。（从最近 Llama3.1 405B 的技术报告中，也可以发现他们在 54 天内碰到了 419 次故障。）</p><h3 id="jit-checkpointing" tabindex="-1">JIT Checkpointing <a class="header-anchor" href="#jit-checkpointing" aria-hidden="true">#</a></h3><p>这篇文章的核心思路是：故障后即时生成检查点进行恢复。</p><p>原理是：</p><ul><li>GPU 中的模型参数和 optimizer 状态，仅在训练中的一小段时间内变化，即 minibatch 的反向传播后到 optimizer 迭代那一步，我们可以追踪这个过程，从而可以在参数更新前/后做故障恢复。</li><li>大模型训练会依赖数据并行，因此当错误发生在 minibatch 中，可以在 replica 中找到相同的模型参数和 optimizer 状态。</li></ul><p>因此他们提出可以检测训练中的故障，然后在（可恢复的）故障发生后进行即时恢复，而无需使用常见的定期 checkpoint 机制（当然后文也提了，你愿意两者结合也可以，作为兜底方法）。这样的好处是只需要重放单个 minibatch 即可，极大缩短了恢复耗时。</p><h2 id="_2-关键技术" tabindex="-1">2. 关键技术 <a class="header-anchor" href="#_2-关键技术" aria-hidden="true">#</a></h2><h3 id="具备领域知识的-api-拦截" tabindex="-1">具备领域知识的 API 拦截 <a class="header-anchor" href="#具备领域知识的-api-拦截" aria-hidden="true">#</a></h3><p>他们拦截了 NCCL 和 CUDA 动态链接库，在发生错误后触发 JIT 机制，而不是终止任务。（为此他们构建了一个动态链接库拦截 NCCL 和 CUDA，转发给后端的代理服务器执行，这很类似于他们在 Singularity 中的工作，为了方便，下文我们就用 Singularity 来指代这个劫持库和代理服务器。）</p><p>在第三章中，Singularity 将检测故障然后执行用户指定的回调函数，保存 CPU 和 GPU 状态，它还可以检测 hang 事件、异步拷贝显存到 CPU 侧。</p><p>在第四章中，Singularity 在正常情况下会记录 API 调用日志，检测故障，在故障发生后保存恢复 CPU、GPU 状态，再重放 API 调用。他们认为 Singularity 这种前后端分离的架构有助于维持用户进程无状态。（性能问题）</p><p>（这章标题提到的领域知识是什么呢？一方面是用户代码会调用到什么 API；另一方面就是训练期间的 NCCL 通信的同步点。）</p><h2 id="_3-侵入用户代码的-jit-机制" tabindex="-1">3. 侵入用户代码的 JIT 机制 <a class="header-anchor" href="#_3-侵入用户代码的-jit-机制" aria-hidden="true">#</a></h2><p>用户仅需要改动自己之前的 python 训练脚本，初始化 Singularity 的动态链接库，并利用它暴露的 C ffi 接口 <code>save_checkpoint</code> 即可。最直观的用法就是，用户使用一个 try-catch 块来执行训练，然后在发生错误时，调用 <code>save_checkpoint</code>。</p><p>他们在 NCCL 做集合通信时，检测是否有 hang 事件，因为这代表着某个节点失败了。在检测到这个失败事件后，他们会从数据并行产生的 replica 里面挑一个正常的节点，复制它的状态恢复故障节点。</p><p>整体流程如下：</p><ol><li>在各个节点检测是否有 hang 事件，可能代表别的节点故障了。</li><li>当 hang 发生以后，各个健康节点把自己的状态拷贝到 checkpoint file（或抽象的分布式存储、乃至直接复制到远端节点中）。</li><li>健康节点通知调度器，在 replica 完成 checkpoint 后，调度器终止任务，重新在排除故障 GPU 的资源组下重新启动任务。</li><li>重启后，加载之前的 checkpoint，继续训练。</li></ol><h3 id="检测通信故障" tabindex="-1">检测通信故障 <a class="header-anchor" href="#检测通信故障" aria-hidden="true">#</a></h3><p>已知：</p><ul><li>目前主流框架中，计算和通信的核函数都是在不同的 CUDA Stream 上的，因此可以并行执行，借助 <code>cudaStreamWaitEvent</code> 去做同步。</li><li>以数据并行为例，optimizer 会在 all reduce 执行完成后，才会更新模型参数，就是在利用 <code>cudaStreamWaitEvent</code> 去等待 NCCL 的集合通信完毕。</li></ul><p>因此，如果任意节点上失败了，all reduce 核函数就会卡住。显然，我们可以用一个看门狗机制去检测 hang 事件。这个机制可以实现在 Singularity 拦截库中，从而是用户无感的。他们拦截了 <code>cudaStreamWaitEvent</code> 和 <code>cudaEventRecord</code>，以及少量 NCCL API。他们在拦截库中，识别出 NCCL 所用的 CUDA Stream，和 NCCL 中的 CUDA Events，加到看门狗的事件列表中，第一次碰到 <code>cudaStreamWaitEvent</code> 的时候就开启一个线程，通过 <code>cudaEventQuery</code> 去查询 cuda events 状态。当某个 cuda event 超时了，就会去触发 <code>save_checkpoint</code>。</p><p>对于 FSDP、PP、TP、MP 等并行范式，也是有效的，同样是依赖 NCCL 的集合通信作为检测点。</p><h3 id="存储-gpu-状态" tabindex="-1">存储 GPU 状态 <a class="header-anchor" href="#存储-gpu-状态" aria-hidden="true">#</a></h3><p>在 <code>save_checkpoint</code> 的回调中，用户可以存储 GPU 侧的模型参数、optimizer 的状态，CPU 侧的迭代轮次、随机数生成器等信息。因为这个回调会在故障发生后被调用，所以回调中不能再使用集合通信，否则一些节点又 hang 住了。</p><p>这里有个难点是在 C++ 中，调用用户的 python 代码，涉及到 python GIL 死锁的问题。看门狗的线程在 C++ 侧，调用用户 python 代码需要获取 GIL，但是 GIL 可能已经被其他 hang 住的线程拿住了。为了解决这个问题，他们的看门狗线程注册了一些 signal handler，通过 pthread_sigqueue 向各个线程发送 SIGUSR1 信号，这个信号会释放 GIL。</p><p>另一个细节是 <code>cudaMemcpy</code> 是在默认流上执行的，和所有的 CUDA Stream 同步，会被 hang 住的 cuda 线程阻塞，需要换一个流进行拷贝。</p><p>同时在做 checkpoint 的过程中也可能会失败，因此 checkpoint 文件都是 rank-specific 的，还会有一个 meta file 用来标识某个 rank 节点是否 checkpoint 完毕，借助它可以识别破损的 checkpoints。</p><h3 id="组装正确的-checkpoint" tabindex="-1">组装正确的 checkpoint <a class="header-anchor" href="#组装正确的-checkpoint" aria-hidden="true">#</a></h3><p>当健康节点完成 checkpoint 后，就会通知调度器，恢复要被替换的节点的任务。在 PP 和 MP 并行范式下，需要确保每个 pipeline stage 或者 model partition 都至少有一个 DP 的 replica 完成了 checkpoint。他们的拦截库暴露了一个 <code>jit_get_checkpoint_path</code> API 给用户的 python 训练脚本。</p><p>如果故障发生在前向、反向传播，或者 all reduce 操作，那健康节点都会卡在 all reduce 通信上，会存下来第 i 个 minibatch 下的模型参数和 optimizer 状态。但是如果是在 all reduce 之后、下一个 minibatch 之前出错的，例如在 optimizer 那里出错，那健康节点就会继续在第 i+1 个 minibatch 上执行前向、反向传播，直到第 i+1 次的 all reduce 卡住，才会发现又节点故障了。这两种情况，其实对于本文提出的 checkpoint 机制来说，都是符合预期的，不会又什么问题，只不过是保存的时机不同。</p><h2 id="_4-用户无感的-jit-机制" tabindex="-1">4. 用户无感的 JIT 机制 <a class="header-anchor" href="#_4-用户无感的-jit-机制" aria-hidden="true">#</a></h2><h3 id="正常状态下的处理" tabindex="-1">正常状态下的处理 <a class="header-anchor" href="#正常状态下的处理" aria-hidden="true">#</a></h3><p>在进程正常运行时，Singularity 就会记录所有的 NCCL、CUDA API 和他们的输入参数，存到一个 log buffer 里面（注意一些参数是需要深拷贝的）。在每次 minibatch 开始的时候，这个 log buffer 就会被清空。</p><p>为了保证正确性，需要所有的 CPU/GPU 交互都经过 CUDA API，因此像是 managed memory 这样的特性，是没法使用的。因为会有在 CPU、GPU 间会有隐式的内存拷贝。好消息是目前没有什么框架会用这套机制。（坏消息是在 Grace-Hopper 上，由于有 C2C Link 的存在，CUDA UVM 不再依赖缺页拷贝的方式，而是直接共享新的 SMMU 和 Cache Line，可以预见这种隐式地址传递会被应用起来）。 如果有这样的隐式内存操作，他们会放弃本章的无感 JIT 机制，回退到上一章的用户可控的 JIT 机制。</p><p>他们还每隔几轮就会验证日志是否正确。（这里提到做校验时仅适用确定性的 CUDA API，没看懂什么意思。）校验开始于反向传播的结束，即将开始 optimizer 阶段的时候，他们首先计算了所有 GPU buffer 的校验和。然后重置 GPU 状态，仅保留模型参数和 optimizer 状态数据，丢弃其他数据和 CUDA handler，重放一遍日志中的 API，执行正向和反向传播，计算 GPU buffer 的校验和。</p><h3 id="对于可恢复的错误" tabindex="-1">对于可恢复的错误 <a class="header-anchor" href="#对于可恢复的错误" aria-hidden="true">#</a></h3><p>为了检测故障，他们同样是实现了一个看门狗，当 hang 事件发生，看门狗会取消所有的在途 API 调用。此时 CPU 侧的 python 代码开始等待，故障恢复后再继续执行。</p><p>当故障被检测到了，GPU 状态被重置到当前 minibatch 开始的地方。</p><p>首先考虑前向、后向传播时的故障：</p><ul><li>GPU 仍然可用：模型参数和 optimizer 状态没有清理，其他的激活、梯度等数据会被释放。这种情况不需要对 GPU 显存进行拷贝做 checkpoint 和恢复，可能是短暂的网络问题或者是别的节点发生了 GPU 相关错误。</li><li>GPU 可用，但是网络或驱动出错了，这种情况需要拷贝显存中的模型参数和 optimizer 状态，重启 Singularity 的后端 server 清理掉错误的状态信息，之后进行重建、恢复。</li><li>GPU 不可用，但是没有硬件错误，可能是 CUDA 某个调用出错导致后续调用全部出错。重启 Singularity 的后端 server 清理掉错误的状态信息，从 DP 的 replica 节点复制显存中的模型参数和 optimizer 状态信息。</li></ul><p>现在的重点是保证有一个 replica 已经存好了未经改动的模型参数和 optimizer 状态。这依赖于：</p><ul><li>所有节点在修改自己的模型参数前，都会经过 NCCL 的 all reduce集合通信。</li><li>所有节点都会卡在这里，直到其他节点进入了集合通信阶段，等价于一个全局的同步点。 因此在单节点错误中，所有的其他 GPU 都会卡在 all reduce 这里。</li></ul><p>恢复阶段，等所有的 GPU 都重置了它们的状态到 minibatch 开始阶段，就重新建立 NCCL 通信。因为是用户无感的，但是重建，所以需要使用 virtual cuda handler，Singularity 内部需要维护这样一个映射。重建完成后，开始重放 API，从而实现了无感保存恢复。</p><p>对于 optimizer 优化步骤中的故障：和第三章的描述一致，只是 i 轮和 i+1 轮的区别。</p><p>因为 Singularity 拦截的 API 太过底层，他们在 pytorch 框架中，增加了额外的 hook 点，区分训练的不同阶段，即前向、反向传播和 optimizer 优化步骤。这个 hook 点是在 pre-optimizer-step 和 post-optimizer-step 处，通知劫持层（同样可以通过 Singularity 的 C ffi）。</p><h3 id="对于不可恢复的错误" tabindex="-1">对于不可恢复的错误 <a class="header-anchor" href="#对于不可恢复的错误" aria-hidden="true">#</a></h3><p>借助 CRIU 迁移 CPU 侧状态。</p><p>使用独特的标记区分模型参数和 optimizer 状态的 GPU buffer。同样由于太过底层，没法使用 pytorch 中的张量名，所以使用了下面的特征来区分：</p><ul><li>buffer 在分配时的调用栈做哈希，来区分 buffer。这个调用栈也是通过 Singularity 来获取的；</li><li>一个序列号，以防多个 buffer 的调用栈相同；</li><li>buffer size。</li></ul><p>故障的 GPU rank 就可以根据 replica 保存的 buffer 来恢复了。</p></div></div></main><!--[--><!--]--><!----><!--[--><!--[--><!--[--><!----><!--]--><!--]--><!--]--></div></div></div></div></div><!----><!--[--><!--]--></div><!----><footer data-v-4f0db67d> Powered by <a href="https://github.com/forsworns/" target="_blank" title="Author" data-v-4f0db67d>Peihao Yang</a> | Copyright © 2019-2024 | MIT License </footer><!--]--></div>
    <script>__VP_HASH_MAP__ = JSON.parse("{\"zh_blogs_20190721_index.md\":\"709361e5\",\"index.md\":\"ee011810\",\"zh_blogs_20190824_index.md\":\"7bcdf8cd\",\"zh_about-me_index.md\":\"c09835fb\",\"about-me_index.md\":\"42dc7420\",\"zh_blogs_20190901_index.md\":\"0887d137\",\"zh_blogs_20190919_index.md\":\"15a7d85b\",\"zh_blogs_20190908_index.md\":\"3a71bef2\",\"zh_blogs_20191112_index.md\":\"80b242f6\",\"zh_blogs_20210315_index.md\":\"abea2477\",\"zh_blogs_20200817_index.md\":\"26f5af0d\",\"zh_blogs_20210310_index.md\":\"f0a88243\",\"zh_blogs_20210311_index.md\":\"eb1ee207\",\"zh_blogs_20210226_index.md\":\"c6471162\",\"zh_blogs_20200616_index.md\":\"40286a23\",\"zh_blogs_20191109_index.md\":\"2471d931\",\"zh_blogs_20210123_index.md\":\"3308ed24\",\"zh_blogs_20210203_index.md\":\"2f0a3d42\",\"zh_blogs_20200816_index.md\":\"e5cafae9\",\"zh_blogs_20210204_index.md\":\"4f2a4ed2\",\"zh_blogs_20210223_index.md\":\"645adb3b\",\"zh_blogs_20200818_index.md\":\"74c5a02e\",\"zh_blogs_20201023_index.md\":\"6dd80596\",\"zh_blogs_20210224_index.md\":\"e40ce42c\",\"zh_blogs_20210312_index.md\":\"ed001cd8\",\"zh_blogs_20210409_index.md\":\"1dcd44df\",\"zh_blogs_20191102_index.md\":\"075f9186\",\"zh_blogs_20210120_index.md\":\"bf0f8c1e\",\"zh_blogs_20210329_index.md\":\"a6ecf0d5\",\"zh_blogs_20210430_index.md\":\"f8b923a8\",\"zh_blogs_20210506_index.md\":\"bdb88a83\",\"zh_blogs_20210412_index.md\":\"abec9455\",\"zh_blogs_20210706_index.md\":\"9ba51a6d\",\"zh_blogs_20210627_index.md\":\"cd7d8056\",\"zh_blogs_20210715_index.md\":\"9e619db7\",\"zh_blogs_20210728_index.md\":\"e778bf9a\",\"zh_blogs_20210801_index.md\":\"3695616f\",\"zh_blogs_20191103_index.md\":\"baa33876\",\"zh_blogs_20211002_index.md\":\"389c287c\",\"zh_blogs_20210822_index.md\":\"0f24e05e\",\"zh_blogs_20220611_index.md\":\"673a8f84\",\"zh_blogs_20220105_index.md\":\"1b937d9e\",\"zh_blogs_20240519_index.md\":\"2fd538d7\",\"zh_blogs_20240903_index.md\":\"eb8dd773\",\"zh_blogs_20240626_index.md\":\"703ec052\",\"zh_blogs_20221108_index.md\":\"ab6a45a2\",\"zh_blogs_20211130_index.md\":\"9a7b67f4\",\"zh_blogs_20211120_index.md\":\"3cb95165\",\"zh_blogs_20230126_index.md\":\"aacd8eb0\",\"zh_blogs_20230121_index.md\":\"bfbc0364\",\"zh_blogs_20230125_index.md\":\"fc629e4a\",\"zh_blogs_20220224_index.md\":\"746e685f\",\"zh_blogs_20220101_index.md\":\"7567a34b\",\"zh_blogs_20240220_index.md\":\"71ad9760\",\"zh_blogs_20240413_index.md\":\"9cae2b73\",\"zh_blogs_20240215_index.md\":\"718e28be\",\"zh_blogs_20240427_index.md\":\"02f28250\",\"zh_blogs_20240513_index.md\":\"269a5e14\",\"zh_blogs_20240526_index.md\":\"620f4905\",\"zh_blogs_20211210_index.md\":\"c6009ee9\",\"zh_blogs_20221024_index.md\":\"6dbd2262\",\"zh_blogs_20240620_index.md\":\"fc1f14ac\",\"zh_blogs_20240622_index.md\":\"c394b364\",\"zh_blogs_20230601_index.md\":\"2bfdbf31\",\"zh_blogs_tags_index.md\":\"e46ba743\",\"zh_blogs_20230201_repost.md\":\"1fc486bc\",\"zh_blogs_20230201_index.md\":\"32468cee\",\"zh_blogs_20240518_index.md\":\"21b6d538\",\"zh_blogs_20230209_index.md\":\"e77c4aa3\",\"zh_blogs_20230322_index.md\":\"53f6d137\",\"zh_index.md\":\"e88a5970\",\"zh_blogs_20220316_index.md\":\"4a9f8f4c\",\"zh_blogs_index.md\":\"0e1b9b31\",\"zh_blogs_20240423_index.md\":\"105b70e4\",\"zh_blogs_20221228_index.md\":\"2f3c09a4\",\"zh_blogs_20240128_index.md\":\"4fd8be53\",\"zh_blogs_20230101_index.md\":\"71dd75cf\",\"zh_blogs_20240623_index.md\":\"b5ec5fd9\"}")</script>
    <script type="module" async src="/assets/app.4f98c8bd.js"></script>
    
  </body>
</html>