<!DOCTYPE html>
<html lang="zh-CN" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>HAMI 源码阅读 | Sharlayan</title>
    <meta name="description" content="第四范式开源的通用 GPU 虚拟化组件">
    <link rel="preload stylesheet" href="/assets/style.3ef9b918.css" as="style">
    <link rel="modulepreload" href="/assets/chunks/VPAlgoliaSearchBox.df3ef109.js">
    <link rel="modulepreload" href="/assets/app.0f5a0ae1.js">
    <link rel="modulepreload" href="/assets/zh_blogs_20241020_index.md.69fa1bf7.lean.js">
    
    <script src="https://cdn.jsdelivr.net/gh/stevenjoezhang/live2d-widget@latest/autoload.js"></script>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/4.0.0/github-markdown.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdn.staticfile.org/ionicons/2.0.1/css/ionicons.min.css">
  <link rel="icon" type="image/png" href="/logo.png">
  <meta name="author" content="Peihao Yang">
  <meta property="og:title" content="Home">
  <meta property="og:description" content="Home of Peihao Yang">
  <script id="check-dark-light">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
  </head>
  <body>
    <div id="app"><!--[--><div class="Layout" data-v-b617430f><!--[--><!--]--><!--[--><span tabindex="-1" data-v-d4120332></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-d4120332> Skip to content </a><!--]--><!----><header class="VPNav no-sidebar" data-v-b617430f data-v-aa1cde23><div class="VPNavBar" data-v-aa1cde23 data-v-cbdd8588><div class="container" data-v-cbdd8588><div class="title" data-v-cbdd8588><div class="VPNavBarTitle" data-v-cbdd8588 data-v-730d6dd1><a class="title" href="/zh/" data-v-730d6dd1><!--[--><!--]--><!--[--><img class="VPImage logo" src="/assets/logo.png" alt data-v-0f13a436><!--]--><!----><!--[--><!--]--></a></div></div><div class="content" data-v-cbdd8588><div class="curtain" data-v-cbdd8588></div><!--[--><!--]--><div class="VPNavBarSearch search" data-v-cbdd8588 style="--699c4559:&#39;Meta&#39;;"><div id="docsearch"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg class="DocSearch-Search-Icon" width="20" height="20" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-cbdd8588 data-v-2d3a777e><span id="main-nav-aria-label" class="visually-hidden" data-v-2d3a777e>Main Navigation</span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/zh/" data-v-2d3a777e data-v-f559a019 data-v-1a0f9836><!--[-->🏡主页<!--]--><!----></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/zh/about-me/" data-v-2d3a777e data-v-f559a019 data-v-1a0f9836><!--[-->🦹‍♂️关于我<!--]--><!----></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-2d3a777e data-v-fc33d832><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-fc33d832><span class="text" data-v-fc33d832><!----> 📓博客 <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="text-icon" data-v-fc33d832><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span></button><div class="menu" data-v-fc33d832><div class="VPMenu" data-v-fc33d832 data-v-ecf4e7d9><div class="items" data-v-ecf4e7d9><!--[--><!--[--><div class="VPMenuLink" data-v-ecf4e7d9 data-v-c7da634f><a class="VPLink link" href="/zh/blogs/" data-v-c7da634f data-v-1a0f9836><!--[-->📃所有博客<!--]--><!----></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-ecf4e7d9 data-v-c7da634f><a class="VPLink link" href="/zh/blogs/tags/" data-v-c7da634f data-v-1a0f9836><!--[-->🔖标签分类<!--]--><!----></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="https://forsworns.github.io/feed.xml" target="_blank" rel="noreferrer" data-v-2d3a777e data-v-f559a019 data-v-1a0f9836><!--[-->🔥RSS<!--]--><!----></a><!--]--><!--]--></nav><div class="VPFlyout VPNavBarTranslations translations" data-v-cbdd8588 data-v-7cdc304e data-v-fc33d832><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-fc33d832><span class="text" data-v-fc33d832><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="option-icon" data-v-fc33d832><path d="M0 0h24v24H0z" fill="none"></path><path d=" M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z " class="css-c4d79v"></path></svg>  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="text-icon" data-v-fc33d832><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span></button><div class="menu" data-v-fc33d832><div class="VPMenu" data-v-fc33d832 data-v-ecf4e7d9><!----><!--[--><!--[--><div class="items" data-v-7cdc304e><p class="title" data-v-7cdc304e>中文</p><!--[--><div class="VPMenuLink" data-v-7cdc304e data-v-c7da634f><a class="VPLink link" href="/" data-v-c7da634f data-v-1a0f9836><!--[-->English<!--]--><!----></a></div><!--]--></div><!--]--><!--]--></div></div></div><div class="VPNavBarAppearance appearance" data-v-cbdd8588 data-v-7f24c201><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" aria-label="toggle dark mode" aria-checked="false" data-v-7f24c201 data-v-2b897f09 data-v-ab7cdc04><span class="check" data-v-ab7cdc04><span class="icon" data-v-ab7cdc04><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="sun" data-v-2b897f09><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="moon" data-v-2b897f09><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-cbdd8588 data-v-a5afa74d data-v-80c99471><!--[--><a class="VPSocialLink" href="https://github.com/forsworns/blog-vitepress" target="_blank" rel="noopener" data-v-80c99471 data-v-51b6609b><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg></a><a class="VPSocialLink" href="mailto:peihao.young@gmail.com" target="_blank" rel="noopener" data-v-80c99471 data-v-51b6609b><svg role="img" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" width="20">
            <path d="M874.666667 375.189333V746.666667a64 64 0 0 1-64 64H213.333333a64 64 0 0 1-64-64V375.189333l266.090667 225.6a149.333333 149.333333 0 0 0 193.152 0L874.666667 375.189333zM810.666667 213.333333a64.789333 64.789333 0 0 1 22.826666 4.181334 63.616 63.616 0 0 1 26.794667 19.413333 64.32 64.32 0 0 1 9.344 15.466667c2.773333 6.570667 4.48 13.696 4.906667 21.184L874.666667 277.333333v21.333334L553.536 572.586667a64 64 0 0 1-79.893333 2.538666l-3.178667-2.56L149.333333 298.666667v-21.333334a63.786667 63.786667 0 0 1 35.136-57.130666A63.872 63.872 0 0 1 213.333333 213.333333h597.333334z" ></path>
            </svg></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-cbdd8588 data-v-e459e5dc data-v-fc33d832><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-fc33d832><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="icon" data-v-fc33d832><circle cx="12" cy="12" r="2"></circle><circle cx="19" cy="12" r="2"></circle><circle cx="5" cy="12" r="2"></circle></svg></button><div class="menu" data-v-fc33d832><div class="VPMenu" data-v-fc33d832 data-v-ecf4e7d9><!----><!--[--><!--[--><div class="group" data-v-e459e5dc><p class="trans-title" data-v-e459e5dc>中文</p><!--[--><div class="VPMenuLink" data-v-e459e5dc data-v-c7da634f><a class="VPLink link" href="/" data-v-c7da634f data-v-1a0f9836><!--[-->English<!--]--><!----></a></div><!--]--></div><div class="group" data-v-e459e5dc><div class="item appearance" data-v-e459e5dc><p class="label" data-v-e459e5dc>Appearance</p><div class="appearance-action" data-v-e459e5dc><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" aria-label="toggle dark mode" aria-checked="false" data-v-e459e5dc data-v-2b897f09 data-v-ab7cdc04><span class="check" data-v-ab7cdc04><span class="icon" data-v-ab7cdc04><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="sun" data-v-2b897f09><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="moon" data-v-2b897f09><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div></div></div><div class="group" data-v-e459e5dc><div class="item social-links" data-v-e459e5dc><div class="VPSocialLinks social-links-list" data-v-e459e5dc data-v-80c99471><!--[--><a class="VPSocialLink" href="https://github.com/forsworns/blog-vitepress" target="_blank" rel="noopener" data-v-80c99471 data-v-51b6609b><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg></a><a class="VPSocialLink" href="mailto:peihao.young@gmail.com" target="_blank" rel="noopener" data-v-80c99471 data-v-51b6609b><svg role="img" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" width="20">
            <path d="M874.666667 375.189333V746.666667a64 64 0 0 1-64 64H213.333333a64 64 0 0 1-64-64V375.189333l266.090667 225.6a149.333333 149.333333 0 0 0 193.152 0L874.666667 375.189333zM810.666667 213.333333a64.789333 64.789333 0 0 1 22.826666 4.181334 63.616 63.616 0 0 1 26.794667 19.413333 64.32 64.32 0 0 1 9.344 15.466667c2.773333 6.570667 4.48 13.696 4.906667 21.184L874.666667 277.333333v21.333334L553.536 572.586667a64 64 0 0 1-79.893333 2.538666l-3.178667-2.56L149.333333 298.666667v-21.333334a63.786667 63.786667 0 0 1 35.136-57.130666A63.872 63.872 0 0 1 213.333333 213.333333h597.333334z" ></path>
            </svg></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-cbdd8588 data-v-d6834c14><span class="container" data-v-d6834c14><span class="top" data-v-d6834c14></span><span class="middle" data-v-d6834c14></span><span class="bottom" data-v-d6834c14></span></span></button></div></div></div><!----></header><!----><!----><div class="VPContent" id="VPContent" data-v-b617430f data-v-f32377af><div class="VPDoc has-aside" data-v-f32377af data-v-1e970af1><div class="container" data-v-1e970af1><div class="aside" data-v-1e970af1><div class="aside-curtain" data-v-1e970af1></div><div class="aside-container" data-v-1e970af1><div class="aside-content" data-v-1e970af1><div class="VPDocAside" data-v-1e970af1 data-v-b1723386><!--[--><!--]--><!--[--><!--]--><div class="VPDocAsideOutline" data-v-b1723386 data-v-0980ba1d><div class="content" data-v-0980ba1d><div class="outline-marker" data-v-0980ba1d></div><div class="outline-title" data-v-0980ba1d>On this page</div><nav aria-labelledby="doc-outline-aria-label" data-v-0980ba1d><span class="visually-hidden" id="doc-outline-aria-label" data-v-0980ba1d> Table of Contents for current page </span><ul class="root" data-v-0980ba1d data-v-6f4caaf4><!--[--><!--]--></ul></nav></div></div><!--[--><!--]--><div class="spacer" data-v-b1723386></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-1e970af1><div class="content-container" data-v-1e970af1><!--[--><!--]--><main class="main" data-v-1e970af1><div style="position:relative;" class="vp-doc _zh_blogs_20241020_index" data-v-1e970af1><div><nav class="table-of-contents"><ul><li><a href="#src-libvgpu-c">src/libvgpu.c</a></li><li><a href="#src-nvml">src/nvml</a><ul><li><a href="#hook-c">hook.c</a></li><li><a href="#nvml-entry-c">nvml_entry.c</a></li></ul></li><li><a href="#src-multiprocess">src/multiprocess</a><ul><li><a href="#shrreg-tool-c">shrreg_tool.c</a></li><li><a href="#multiprocess-memory-limit-c">multiprocess_memory_limit.c</a></li><li><a href="#multiprocess-utilization-watcher-c">multiprocess_utilization_watcher.c</a></li></ul></li><li><a href="#src-allocator-allocator-c">src/allocator/allocator.c</a></li><li><a href="#src-cuda">src/cuda/</a><ul><li><a href="#memory-c">memory.c</a></li></ul></li><li><a href="#src-utils-c">src/utils.c</a></li><li><a href="#include">include</a><ul><li><a href="#libnvml-hook-h">libnvml_hook.h</a></li><li><a href="#libcuda-hook-h">libcuda_hook.h</a></li></ul></li></ul></nav><p>第四范式开源的通用 GPU 虚拟化组件，支持多家 GPU 产品，目前只做了切分功能，已进 CNCF。比较像之前腾讯开源的 <a href="https://github.com/tkestack/gpu-manager" target="_blank" rel="noreferrer">https://github.com/tkestack/gpu-manager</a> 和对应的 <a href="https://github.com/tkestack/vcuda-controller%EF%BC%8C%E4%B9%8B%E5%89%8D%E4%B8%80%E7%9B%B4%E6%B2%A1%E4%BB%94%E7%BB%86%E8%AF%BB%EF%BC%8C%E5%88%9A%E5%A5%BD%E8%AF%BB%E4%B8%8B%E8%BF%99%E4%B8%AA%E8%BF%9B%E4%BA%86" target="_blank" rel="noreferrer">https://github.com/tkestack/vcuda-controller，之前一直没仔细读，刚好读下这个进了</a> CNCF 的吧。</p><h1 id="hami-core" tabindex="-1">HAMi-core <a class="header-anchor" href="#hami-core" aria-hidden="true">#</a></h1><p><a href="https://github.com/Project-HAMi/HAMi-core" target="_blank" rel="noreferrer">https://github.com/Project-HAMi/HAMi-core</a> 基于主线 6b2aed490910db1a33c6575ba81b1ecd96fce5f4</p><h2 id="src-libvgpu-c" tabindex="-1">src/libvgpu.c <a class="header-anchor" href="#src-libvgpu-c" aria-hidden="true">#</a></h2><p>劫持 <a href="http://libcuda.so" target="_blank" rel="noreferrer">libcuda.so</a> 和 <a href="http://libnvidia-ml.so" target="_blank" rel="noreferrer">libnvidia-ml.so</a> 的方法是通过劫持 dlsym 函数，如果用户查询的某个符号是 HAMI-core 可以拦截的，就返回对应的拦截函数。dlsym 则是通过暴露一个同名符号，通过 LD_PRELOAD 等方式对 libdl 做覆盖拦截。</p><h2 id="src-nvml" tabindex="-1">src/nvml <a class="header-anchor" href="#src-nvml" aria-hidden="true">#</a></h2><h3 id="hook-c" tabindex="-1">hook.c <a class="header-anchor" href="#hook-c" aria-hidden="true">#</a></h3><p>做了改动的一些 NVML API，查初始化的时候构造的真实函数指针表调用过去。最重要的就是 <code>_nvmlDeviceGetMemoryInfo</code> 这个实现。</p><p><code>_nvmlDeviceGetMemoryInfo</code> 里面 <code>nvmlDeviceGetIndex</code> 获取到设备的 id，通过 <code>nvml_to_cuda_map()</code> 转换成 <code>shared_region_info_t</code> 中用于标识虚拟设备的 id。根据 id 查询 <code>shared_region_info_t</code> 类型的全局单例 <code>region_info</code>，获取当前虚拟设备的显存限制和使用情况。</p><h3 id="nvml-entry-c" tabindex="-1">nvml_entry.c <a class="header-anchor" href="#nvml-entry-c" aria-hidden="true">#</a></h3><p>没有做改动直接调用下去的 NVML API。</p><h2 id="src-multiprocess" tabindex="-1">src/multiprocess <a class="header-anchor" href="#src-multiprocess" aria-hidden="true">#</a></h2><h3 id="shrreg-tool-c" tabindex="-1">shrreg_tool.c <a class="header-anchor" href="#shrreg-tool-c" aria-hidden="true">#</a></h3><p>一个命令行小工具，支持几个选项：</p><ul><li>create_new：创建了一个文件 <code>/tmp/cudevshr.cache</code>，后面会被用来做跨进程的共享区域，它只是保证这个文件存在。</li><li>Suspend/resume：对所有运行中的被监控到的进程执行 <code>SIGUSR1</code> 和 <code>SIGUSR2</code> 分别用于恢复和挂起这些任务。</li></ul><h3 id="multiprocess-memory-limit-c" tabindex="-1">multiprocess_memory_limit.c <a class="header-anchor" href="#multiprocess-memory-limit-c" aria-hidden="true">#</a></h3><p>这个文件里面比较杂，主要是 HAMI 的多进程资源使用情况的共享内存文件缓存、基于这个共享内存实现的显存管理、还有一些工具函数如host/container pid 转换、共享内存的加锁（lock_shrreg、unlock_shrreg ），虽然看文件名只是做显存限制的。vcuda-controller 里面实现的比较简单，就是在一个文件里面存了下每个进程的 pid，然后每个 API 调用都会调用 <code>nvmlDeviceGetComputeRunningProcesses</code> 去查然后去对 pid 做匹配，为了省时，搜索的时候对 pid 做了二分，总体上开销还是比较高的。HAMI 这里则是通过直接创建一个多进程共享的资源消耗统计文件，进行了缓存，减少 NVML API 调用次数。这个共享文件会被 mmap 到每个进程内，也就是 <code>shared_region_t</code> 类型的 <code>region_info.shared_region</code>。</p><p>初始化过程中主要做了两件事 <code>try_create_shrreg()</code> 和 <code>init_proc_slot_withlock()</code>。<code>try_create_shrreg</code> 就是创建、初始化上面提到的共享文件的过程。<code>init_proc_slot_withlock</code> 则是对共享内存中当前进程的 slot 做了初始化。为 <code>SIGUSR1</code> 和 <code>SIGUSR1</code> 分别注册信号处理函数 <code>sig_restore_stub</code> 和 <code>sig_swap_stub</code>。</p><p>那么有了上面的共享内存，HAMI 中就不是通过 NVML 去查询显存占用了，而是通过 <code>get_gpu_memory_usage</code> 直接查询共享内存缓存中的统计数据。那么它又是如何收集这个统计数据的呢？这就涉及到了另一个比较有趣的函数是 <code>add_gpu_device_memory_usage</code>，它在涉及到显存剧烈变化的 CUDA API 执行时被调用，用来修改共享内存中的显存消耗统计数据，同时它还支持对显存进行分类，区分了是 CUcontext 相关、CUmodule相关、数据相关三类。但是读完代码发现，其实只有通过 cuda API 分配的数据显存被准确统计到了，不知道是不是他们内部实现没有开源出来。CUmodule 实际上完全没统计，CUcontext 则是用了一下初始化后 primary context 的消耗去计算，不过除了 primary context，一般上层框架也基本没有自己去创建 CUcontext 的（其他厂商，AMD ROCm 甚至实际上没有区分 device 和 context）。</p><h3 id="multiprocess-utilization-watcher-c" tabindex="-1">multiprocess_utilization_watcher.c <a class="header-anchor" href="#multiprocess-utilization-watcher-c" aria-hidden="true">#</a></h3><p>对 cuda core 进行分配，与 vcuda-controller 中类似。</p><p><code>cuda_to_nvml_map</code> 变量定义在这里，在别的地方 extern 引用了。全局变量 <code>g_cycle</code> 为 10ms，<code>g_wait</code> 为 120ms。</p><p>几个重要的函数，<code>setspec()</code> 用于计算 cuda core 的总数。这里的 FACTOR 是 32，没太搞懂为啥，A100 每个 SM 是 64 个 cuda core，L20、H100 GPU 每个 SM 上是 128 个 cuda core，当然也可能这里表示的是 CUDA 一个 SM 上的 wrap size 是 32。over-subscription 的话有允许调度多个线程，所以是乘起来。感觉只是一个软性的估计，下面的限流器实现其实也可以看出来是允许超过限制的。</p><div class="language-"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki material-palenight"><code><span class="line"><span style="color:#A6ACCD;">int setspec() {</span></span>
<span class="line"><span style="color:#A6ACCD;">    CHECK_CU_RESULT(cuDeviceGetAttribute(&amp;g_sm_num,CU_DEVICE_ATTRIBUTE_MULTIPROCESSOR_COUNT,0));</span></span>
<span class="line"><span style="color:#A6ACCD;">    CHECK_CU_RESULT(cuDeviceGetAttribute(&amp;g_max_thread_per_sm,CU_DEVICE_ATTRIBUTE_MAX_THREADS_PER_MULTIPROCESSOR,0));</span></span>
<span class="line"><span style="color:#A6ACCD;">    g_total_cuda_cores = g_max_thread_per_sm * g_sm_num * FACTOR;</span></span>
<span class="line"><span style="color:#A6ACCD;">    return 0;</span></span>
<span class="line"><span style="color:#A6ACCD;">}</span></span>
<span class="line"><span style="color:#A6ACCD;"></span></span></code></pre></div><p><code>rate_limiter()</code> 是对 utilization 做限制的核心实现（注意 nvidia-smi 看到 utilization 是一个时分的统计数据，这里从 cuda core 的角度去限制实际上是空分的），在 <code>cuLaunchKernel</code> 被调用的时候先触发它，用来限流。加载核函数的 grid 参数被用来计算需要占用的 cuda core 数量。这里在限流的时候，留了一个优先级的接口，<code>region_info.shared_region-&gt;priority</code> 目前看没啥实际用途。（NSDI 23 的一个类似的工作 <a href="https://github.com/pkusys/TGS%EF%BC%8C%E5%81%9A%E4%BA%86%E4%BC%98%E5%85%88%E7%BA%A7%E8%B0%83%E5%BA%A6%EF%BC%8C%E7%AE%80%E5%8D%95%E7%9C%8B%E4%BA%86%E4%B8%8B%E4%BB%A3%E7%A0%81%E9%83%BD%E6%98%AF%E5%90%8C%E6%A0%B9%E7%94%9F~%EF%BC%89%E3%80%82%E7%B2%BE%E7%AE%80%E5%90%8E%E6%A0%B8%E5%BF%83%E5%A6%82%E4%B8%8B" target="_blank" rel="noreferrer">https://github.com/pkusys/TGS，做了优先级调度，简单看了下代码都是同根生~）。精简后核心如下</a></p><div class="language-cpp"><button title="Copy Code" class="copy"></button><span class="lang">cpp</span><pre class="shiki material-palenight"><code><span class="line"><span style="color:#676E95;font-style:italic;">// 同样没有用 block，按 vcuda-controller 那边的解释，他们是认为 block 的影响没有 grid 大所以只用了 grid，所以只是留了一个参数给其他算法实现</span></span>
<span class="line"><span style="color:#C792EA;">void</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">rate_limiter</span><span style="color:#89DDFF;">(</span><span style="color:#C792EA;">int</span><span style="color:#A6ACCD;"> </span><span style="color:#A6ACCD;font-style:italic;">grids</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#C792EA;">int</span><span style="color:#A6ACCD;"> </span><span style="color:#A6ACCD;font-style:italic;">blocks</span><span style="color:#89DDFF;">)</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">{</span></span>
<span class="line"><span style="color:#A6ACCD;">  	</span><span style="color:#C792EA;">int</span><span style="color:#A6ACCD;"> before_cuda_cores </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#F78C6C;">0</span><span style="color:#89DDFF;">;</span></span>
<span class="line"><span style="color:#A6ACCD;">  	</span><span style="color:#C792EA;">int</span><span style="color:#A6ACCD;"> after_cuda_cores </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#F78C6C;">0</span><span style="color:#89DDFF;">;</span></span>
<span class="line"><span style="color:#A6ACCD;">	</span><span style="color:#C792EA;">int</span><span style="color:#A6ACCD;"> kernel_size </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> grids</span><span style="color:#89DDFF;">;</span></span>
<span class="line"><span style="color:#A6ACCD;">    	</span><span style="color:#89DDFF;font-style:italic;">do</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">{</span></span>
<span class="line"><span style="color:#F07178;">      		before_cuda_cores </span><span style="color:#89DDFF;">=</span><span style="color:#F07178;"> g_cur_cuda_cores</span><span style="color:#89DDFF;">;</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;">		// cuda core 不够了，进入睡眠，每 10ms 检查一次 cuda core 资源，等待别的核函数跑完释放了 cuda core，再提交新的核函数。</span></span>
<span class="line"><span style="color:#F07178;">      		</span><span style="color:#89DDFF;font-style:italic;">if</span><span style="color:#F07178;"> </span><span style="color:#89DDFF;">(</span><span style="color:#F07178;">before_cuda_cores </span><span style="color:#89DDFF;">&lt;</span><span style="color:#F07178;"> </span><span style="color:#F78C6C;">0</span><span style="color:#89DDFF;">)</span><span style="color:#F07178;"> </span><span style="color:#89DDFF;">{</span></span>
<span class="line"><span style="color:#F07178;">        		</span><span style="color:#82AAFF;">nanosleep</span><span style="color:#89DDFF;">(&amp;</span><span style="color:#F07178;">g_cycle</span><span style="color:#89DDFF;">,</span><span style="color:#F07178;"> </span><span style="color:#89DDFF;">NULL);</span></span>
<span class="line"><span style="color:#F07178;">			</span><span style="color:#89DDFF;font-style:italic;">continue</span><span style="color:#89DDFF;">;</span></span>
<span class="line"><span style="color:#F07178;">      		</span><span style="color:#89DDFF;">}</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;">		// 更新如果加载了核函数，会剩余的 cuda core 数量。按这种实现，用户可以使用远超过限制的 cuda core？</span></span>
<span class="line"><span style="color:#F07178;">      		after_cuda_cores </span><span style="color:#89DDFF;">=</span><span style="color:#F07178;"> before_cuda_cores </span><span style="color:#89DDFF;">-</span><span style="color:#F07178;"> kernel_size</span><span style="color:#89DDFF;">;</span></span>
<span class="line"><span style="color:#F07178;">    	</span><span style="color:#89DDFF;">}</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;font-style:italic;">while</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">(!</span><span style="color:#82AAFF;">CAS</span><span style="color:#89DDFF;">(&amp;</span><span style="color:#A6ACCD;">g_cur_cuda_cores</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> before_cuda_cores</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> after_cuda_cores</span><span style="color:#89DDFF;">));</span></span>
<span class="line"><span style="color:#89DDFF;">}</span></span>
<span class="line"></span></code></pre></div><p><code>utilization_watcher</code> 是一个进程内的守护线程，在 <code>src/libvgpu.c</code> 中通过 <code>init_utilization_watcher()</code> 在初始化完成后创建，以 <code>g_wait</code> 为周期重新分配 cuda core 计算资源，较 vcuda-controller 中的 cuda core 分配策略做了很大的删减，代码简化后如下，</p><div class="language-cpp"><button title="Copy Code" class="copy"></button><span class="lang">cpp</span><pre class="shiki material-palenight"><code><span class="line"><span style="color:#C792EA;">void*</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">utilization_watcher</span><span style="color:#89DDFF;">()</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">{</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#C792EA;">int</span><span style="color:#A6ACCD;"> userutil</span><span style="color:#89DDFF;">[</span><span style="color:#A6ACCD;">CUDA_DEVICE_MAX_COUNT</span><span style="color:#89DDFF;">];</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#C792EA;">int</span><span style="color:#A6ACCD;"> sysprocnum</span><span style="color:#89DDFF;">;</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#C792EA;">int</span><span style="color:#A6ACCD;"> share </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#F78C6C;">0</span><span style="color:#89DDFF;">;</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#C792EA;">int</span><span style="color:#A6ACCD;"> upper_limit </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">get_current_device_sm_limit</span><span style="color:#89DDFF;">(</span><span style="color:#F78C6C;">0</span><span style="color:#89DDFF;">);</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;font-style:italic;">while</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">(</span><span style="color:#F78C6C;">1</span><span style="color:#89DDFF;">){</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;">	// 120ms 更新一次分配</span></span>
<span class="line"><span style="color:#F07178;">        </span><span style="color:#82AAFF;">nanosleep</span><span style="color:#89DDFF;">(&amp;</span><span style="color:#F07178;">g_wait</span><span style="color:#89DDFF;">,</span><span style="color:#F07178;"> </span><span style="color:#89DDFF;">NULL);</span></span>
<span class="line"><span style="color:#F07178;">        </span><span style="color:#89DDFF;font-style:italic;">if</span><span style="color:#F07178;"> </span><span style="color:#89DDFF;">(</span><span style="color:#F07178;">pidfound</span><span style="color:#89DDFF;">==</span><span style="color:#F78C6C;">0</span><span style="color:#89DDFF;">)</span><span style="color:#F07178;"> </span><span style="color:#89DDFF;">{</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;">	  // 在 `region_info.shared_region-&gt;procs` 中注册自己，目前代码中写死了最多支持 1024 个进程。</span></span>
<span class="line"><span style="color:#F07178;">          </span><span style="color:#82AAFF;">update_host_pid</span><span style="color:#89DDFF;">();</span></span>
<span class="line"><span style="color:#F07178;">        </span><span style="color:#89DDFF;">}</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;">	// 设置进程 sm 利用率为 0</span></span>
<span class="line"><span style="color:#F07178;">        </span><span style="color:#82AAFF;">init_gpu_device_sm_utilization</span><span style="color:#89DDFF;">();</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;">	// 这里实际上拿到了多卡的信息，而且和 vcuda-controller 不同的是它是会把查询结果写到一个共享文件里面做缓存。</span></span>
<span class="line"><span style="color:#F07178;">        </span><span style="color:#82AAFF;">get_used_gpu_utilization</span><span style="color:#89DDFF;">(</span><span style="color:#F07178;">userutil</span><span style="color:#89DDFF;">,&amp;</span><span style="color:#F07178;">sysprocnum</span><span style="color:#89DDFF;">);</span></span>
<span class="line"><span style="color:#F07178;">        </span><span style="color:#89DDFF;font-style:italic;">if</span><span style="color:#F07178;"> </span><span style="color:#89DDFF;">((</span><span style="color:#F07178;">share</span><span style="color:#89DDFF;">==</span><span style="color:#F07178;">g_total_cuda_cores</span><span style="color:#89DDFF;">)</span><span style="color:#F07178;"> </span><span style="color:#89DDFF;">&amp;&amp;</span><span style="color:#F07178;"> </span><span style="color:#89DDFF;">(</span><span style="color:#F07178;">g_cur_cuda_cores</span><span style="color:#89DDFF;">&lt;</span><span style="color:#F78C6C;">0</span><span style="color:#89DDFF;">))</span><span style="color:#F07178;"> </span><span style="color:#89DDFF;">{</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;">	  // 这里没看懂</span></span>
<span class="line"><span style="color:#F07178;">          g_total_cuda_cores </span><span style="color:#89DDFF;">*=</span><span style="color:#F07178;"> </span><span style="color:#F78C6C;">2</span><span style="color:#89DDFF;">;</span></span>
<span class="line"><span style="color:#F07178;">          share </span><span style="color:#89DDFF;">=</span><span style="color:#F07178;"> g_total_cuda_cores</span><span style="color:#89DDFF;">;</span></span>
<span class="line"><span style="color:#F07178;">        </span><span style="color:#89DDFF;">}</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;">	// 但是按这里的写法，当前是只支持了单卡，没有利用到上一步取出的多卡信息，</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;">	// 根据利用率限制、当前的利用率、上次的变化值，计算这次分配额度的变化</span></span>
<span class="line"><span style="color:#F07178;">        share </span><span style="color:#89DDFF;">=</span><span style="color:#F07178;"> </span><span style="color:#82AAFF;">delta</span><span style="color:#89DDFF;">(</span><span style="color:#F07178;">upper_limit</span><span style="color:#89DDFF;">,</span><span style="color:#F07178;"> </span><span style="color:#A6ACCD;">userutil</span><span style="color:#89DDFF;">[</span><span style="color:#F78C6C;">0</span><span style="color:#89DDFF;">],</span><span style="color:#F07178;"> share</span><span style="color:#89DDFF;">);</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;">	// 应用计算出的额度变化，重新配置 `g_cur_cuda_cores`</span></span>
<span class="line"><span style="color:#F07178;">        </span><span style="color:#82AAFF;">change_token</span><span style="color:#89DDFF;">(</span><span style="color:#F07178;">share</span><span style="color:#89DDFF;">);</span></span>
<span class="line"><span style="color:#F07178;">    </span><span style="color:#89DDFF;">}</span></span>
<span class="line"><span style="color:#89DDFF;">}</span></span>
<span class="line"></span></code></pre></div><p>上面通过在 <code>get_used_gpu_utilization()</code> 内，调用 <code>nvmlDeviceGetComputeRunningProcesses</code> 获取所有正在使用某个 GPU 设备的进程，然后调用 <code>nvmlDeviceGetProcessUtilization</code> 获取每个进程的 GPU 利用率和显存占用，分别记录到了 <code>region_info.shared_region-&gt;procs[i].device_util[dev].sm_util</code> 和 <code>region_info.shared_region-&gt;procs[i].monitorused[dev]</code>。这个函数是考虑了多进程的。</p><h2 id="src-allocator-allocator-c" tabindex="-1">src/allocator/allocator.c <a class="header-anchor" href="#src-allocator-allocator-c" aria-hidden="true">#</a></h2><p><code>allocated_list</code> 是一个存了 <code>allocated_device_memory_struct</code> 的双向链表，实例化了两个全局变量 <code>device_overallocated</code>、<code>array_list</code>。成员定义如下</p><div class="language-cpp"><button title="Copy Code" class="copy"></button><span class="lang">cpp</span><pre class="shiki material-palenight"><code><span class="line"><span style="color:#C792EA;">struct</span><span style="color:#F07178;"> </span><span style="color:#FFCB6B;">allocated_device_memory_struct</span><span style="color:#89DDFF;">{</span></span>
<span class="line"><span style="color:#F07178;">    CUdeviceptr address</span><span style="color:#89DDFF;">;</span></span>
<span class="line"><span style="color:#F07178;">    </span><span style="color:#C792EA;">size_t</span><span style="color:#F07178;"> length</span><span style="color:#89DDFF;">;</span></span>
<span class="line"><span style="color:#F07178;">    CUcontext ctx</span><span style="color:#89DDFF;">;</span></span>
<span class="line"><span style="color:#F07178;">    CUmemGenericAllocationHandle </span><span style="color:#89DDFF;">*</span><span style="color:#F07178;">allocHandle</span><span style="color:#89DDFF;">;</span></span>
<span class="line"><span style="color:#89DDFF;">};</span></span>
<span class="line"></span></code></pre></div><p><code>region_list</code> 是一个存了 <code>region_struct</code> 的双向链表，实例化成了一个全局变量 ``r_list。成员定义如下</p><div class="language-cpp"><button title="Copy Code" class="copy"></button><span class="lang">cpp</span><pre class="shiki material-palenight"><code><span class="line"><span style="color:#C792EA;">struct</span><span style="color:#F07178;"> </span><span style="color:#FFCB6B;">region_struct</span><span style="color:#89DDFF;">{</span></span>
<span class="line"><span style="color:#F07178;">    </span><span style="color:#C792EA;">size_t</span><span style="color:#F07178;"> start</span><span style="color:#89DDFF;">;</span></span>
<span class="line"><span style="color:#F07178;">    </span><span style="color:#C792EA;">size_t</span><span style="color:#F07178;"> freemark</span><span style="color:#89DDFF;">;</span></span>
<span class="line"><span style="color:#F07178;">    </span><span style="color:#C792EA;">size_t</span><span style="color:#F07178;"> freed_map</span><span style="color:#89DDFF;">;</span></span>
<span class="line"><span style="color:#F07178;">    </span><span style="color:#C792EA;">size_t</span><span style="color:#F07178;"> length</span><span style="color:#89DDFF;">;</span></span>
<span class="line"><span style="color:#F07178;">    CUcontext ctx</span><span style="color:#89DDFF;">;</span></span>
<span class="line"><span style="color:#F07178;">    allocated_list </span><span style="color:#89DDFF;">*</span><span style="color:#F07178;">region_allocs</span><span style="color:#89DDFF;">;</span></span>
<span class="line"><span style="color:#F07178;">    </span><span style="color:#C792EA;">char</span><span style="color:#F07178;"> </span><span style="color:#89DDFF;">*</span><span style="color:#F07178;">bitmap</span><span style="color:#89DDFF;">;</span></span>
<span class="line"><span style="color:#F07178;">    CUmemGenericAllocationHandle </span><span style="color:#89DDFF;">*</span><span style="color:#F07178;">allocHandle</span><span style="color:#89DDFF;">;</span></span>
<span class="line"><span style="color:#89DDFF;">};</span></span>
<span class="line"></span></code></pre></div><p>OVERSIZE 128M，IPCSIZE 2M，ALIGN 也是 2M。</p><p><code>oom_check()</code> 就是查询了上面提到的记录着进程信息的共享内存区域，获取当前设备的显存用量，加上请求分配的显存值，和设定的限制值做比较。如果超过限制，就尝试清理下已经结束的进程的显存记录，然后重新计算一遍。</p><p>剩下的接口就都是对 cuda 显存分配的一些抽象，把分配结果记录到上面创建的全局列表里面。他们底层又对应着 <code>add_chunk_async()</code></p><div class="language-cpp"><button title="Copy Code" class="copy"></button><span class="lang">cpp</span><pre class="shiki material-palenight"><code><span class="line"><span style="color:#C792EA;">int</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">allocate_raw</span><span style="color:#89DDFF;">(</span><span style="color:#FFCB6B;">CUdeviceptr</span><span style="color:#A6ACCD;"> </span><span style="color:#C792EA;">*</span><span style="color:#A6ACCD;font-style:italic;">dptr</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#C792EA;">size_t</span><span style="color:#A6ACCD;"> </span><span style="color:#A6ACCD;font-style:italic;">size</span><span style="color:#89DDFF;">);</span></span>
<span class="line"><span style="color:#C792EA;">int</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">free_raw</span><span style="color:#89DDFF;">(</span><span style="color:#FFCB6B;">CUdeviceptr</span><span style="color:#A6ACCD;"> </span><span style="color:#A6ACCD;font-style:italic;">dptr</span><span style="color:#89DDFF;">);</span></span>
<span class="line"><span style="color:#C792EA;">int</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">add_chunk_only</span><span style="color:#89DDFF;">(</span><span style="color:#FFCB6B;">CUdeviceptr</span><span style="color:#A6ACCD;"> </span><span style="color:#A6ACCD;font-style:italic;">address</span><span style="color:#89DDFF;">,</span><span style="color:#C792EA;">size_t</span><span style="color:#A6ACCD;"> </span><span style="color:#A6ACCD;font-style:italic;">size</span><span style="color:#89DDFF;">);</span></span>
<span class="line"><span style="color:#C792EA;">int</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">allocate_async_raw</span><span style="color:#89DDFF;">(</span><span style="color:#FFCB6B;">CUdeviceptr</span><span style="color:#A6ACCD;"> </span><span style="color:#C792EA;">*</span><span style="color:#A6ACCD;font-style:italic;">dptr</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#C792EA;">size_t</span><span style="color:#A6ACCD;"> </span><span style="color:#A6ACCD;font-style:italic;">size</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#FFCB6B;">CUstream</span><span style="color:#A6ACCD;"> </span><span style="color:#A6ACCD;font-style:italic;">hStream</span><span style="color:#89DDFF;">);</span><span style="color:#676E95;font-style:italic;"> // 基于 add_chunk_async</span></span>
<span class="line"><span style="color:#C792EA;">int</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">free_raw_async</span><span style="color:#89DDFF;">(</span><span style="color:#FFCB6B;">CUdeviceptr</span><span style="color:#A6ACCD;"> </span><span style="color:#A6ACCD;font-style:italic;">dptr</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#FFCB6B;">CUstream</span><span style="color:#A6ACCD;"> </span><span style="color:#A6ACCD;font-style:italic;">hStream</span><span style="color:#89DDFF;">);</span></span>
<span class="line"></span></code></pre></div><p><code>check_memory_type()</code> 就是在 <code>device_overallocated</code> 里面检查有没有查询的指针，判断是设备地址还是 host 侧地址。值得注意的是按这个实现，<code>cuMemAllocManaged</code> 分配出来的地址算到了设备地址里面。</p><h2 id="src-cuda" tabindex="-1">src/cuda/ <a class="header-anchor" href="#src-cuda" aria-hidden="true">#</a></h2><p><a href="http://libcuda.so" target="_blank" rel="noreferrer">libcuda.so</a> 库劫持逻辑，好多 API 其实没实现劫持方案，只是打印了一下日志，感觉是之后打算做。劫持的时候注意一下 <code>cuGetProcAddress</code> 即可。</p><h3 id="memory-c" tabindex="-1">memory.c <a class="header-anchor" href="#memory-c" aria-hidden="true">#</a></h3><p>劫持了显存分配 API，逻辑上就是先调用 <code>oom_check()</code> 检查一下，如果超过显存限制，就不分配了直接返回 OOM。</p><p>比较特殊的是 <code>cuMemHostAlloc</code>、<code>cuMemAllocHost_v2</code>、<code>cuMemHostRegister_v2</code>，这三个 API，则是先真实触发进行分配，再调用 <code>oom_check()</code> 检查显存，如果超了，就释放掉回滚刚刚到真实分配。这个逻辑感觉很迷惑，这三个 API 的分配并没有涉及到对 <code>src/allocator/allocator.c</code> 中的全局链表的修改，也就是说分配前后实际上检查的效果是一样的，为什么要先分配再回滚呢？</p><h2 id="src-utils-c" tabindex="-1">src/utils.c <a class="header-anchor" href="#src-utils-c" aria-hidden="true">#</a></h2><p>定义了一个跨进程的锁，<code>&quot;/tmp/vgpulock/lock”</code>，<code>try_lock_unified_lock</code> 通过标记 <code>O_EXCL</code> 互斥地打开该文件作为锁。</p><p><code>parse_cuda_visible_env</code> 查看环境变量中 <code>CUDA_VISIBLE_DEVICES</code>，尝试对卡的序号进行修正，存到 <code>cuda_to_nvml_map</code> 里面。那这里实际上只支持 nvidia-container-toolkit 对应的 runc 场景，其他厂商都还需要适配。比如昇腾，他们接入 HAMI，是也拿 <code>CUDA_VISIBLE_DEVICES</code> 去做自己的 runc 配置的环境变量了么。</p><p><code>mergepid</code> 接收两个 <code>nvmlDeviceGetComputeRunningProcesses</code> 采集到的进程组，合并到一个里面。实际上不要这个函数也行，反正现在只支持单卡，这个函数只是为了对多卡的<code>nvmlDeviceGetComputeRunningProcesses</code> 返回结果做聚合。</p><p><code>getextrapid</code> 比较两个<code>nvmlDeviceGetComputeRunningProcesses</code> 采集到的进程组，找到新增的那一个进程。</p><p><code>set_task_pid</code> 是为容器内 pid 和 host 侧 pid 建立关联，因为 <code>nvmlDeviceGetComputeRunningProcesses</code> 可以获取到占用 GPU 设备的 host 侧进程号。先调用一次<code>mergepid</code> 将所有占用 GPU 的进程记录到 <code>pre_pids_on_device</code>。<code>cuDevicePrimaryCtxRetain</code> 之后（看上去没激活 ctx 的话不会被 nvml 检测到？），再调用一次 <code>mergepid</code>把所有占用 GPU 的进程记录到 <code>pids_on_device</code>，然后通过<code>getextrapid</code>过滤出来一个新增的进程，就是当前进程在 host 侧的进程号，然后它通过 <code>set_host_pid</code> 把这个 hostpid 写入到 region_info 的共享内存当前进程的分区中。如果有恰好在查找过程中退出的进程，没有影响，因为我们只关心新增的进程，而别的新增进程还卡在 <code>try_lock_unified_lock</code> 那里。</p><h2 id="include" tabindex="-1">include <a class="header-anchor" href="#include" aria-hidden="true">#</a></h2><h3 id="libnvml-hook-h" tabindex="-1">libnvml_hook.h <a class="header-anchor" href="#libnvml-hook-h" aria-hidden="true">#</a></h3><p>定义了宏如 NVML_OVERRIDE_CALL，和用于标识 NVML API 的枚举 NVML_OVERRIDE_ENUM_t。实现上不够简洁很多地方可以 #include 同一个 API 列表去做替换。也没看到生成这些头文件的相关脚本，后面升级更新 API 列表很麻烦。</p><h3 id="libcuda-hook-h" tabindex="-1">libcuda_hook.h <a class="header-anchor" href="#libcuda-hook-h" aria-hidden="true">#</a></h3><p>类似 libnvml_hook.h</p><h1 id="hami" tabindex="-1">HAMi <a class="header-anchor" href="#hami" aria-hidden="true">#</a></h1><p><a href="https://github.com/Project-HAMi/HAMi" target="_blank" rel="noreferrer">https://github.com/Project-HAMi/HAMi</a></p></div></div></main><!--[--><!--]--><!----><!--[--><!--[--><!--[--><!----><!--]--><!--]--><!--]--></div></div></div></div></div><!----><!--[--><!--]--></div><!----><footer data-v-4f0db67d> Powered by <a href="https://github.com/forsworns/" target="_blank" title="Author" data-v-4f0db67d>Peihao Yang</a> | Copyright © 2019-2024 | MIT License </footer><!--]--></div>
    <script>__VP_HASH_MAP__ = JSON.parse("{\"about-me_index.md\":\"ae155f90\",\"zh_blogs_20190721_index.md\":\"4f1bd34e\",\"zh_blogs_20190901_index.md\":\"0f58967a\",\"zh_blogs_20190824_index.md\":\"c9e31211\",\"index.md\":\"431bcd57\",\"zh_blogs_20190919_index.md\":\"660a84aa\",\"zh_about-me_index.md\":\"cb485e9f\",\"zh_blogs_20190908_index.md\":\"b837c695\",\"zh_blogs_20201023_index.md\":\"848aa516\",\"zh_blogs_20210226_index.md\":\"043359b1\",\"zh_blogs_20210310_index.md\":\"bb00b880\",\"zh_blogs_20210311_index.md\":\"2bdad88d\",\"zh_blogs_20210204_index.md\":\"97569ac5\",\"zh_blogs_20210224_index.md\":\"8bf1d3c9\",\"zh_blogs_20210203_index.md\":\"6662f4c7\",\"zh_blogs_20191109_index.md\":\"f3f202fd\",\"zh_blogs_20200818_index.md\":\"e18d8843\",\"zh_blogs_20210123_index.md\":\"1fe092d1\",\"zh_blogs_20210120_index.md\":\"87b674e6\",\"zh_blogs_20200817_index.md\":\"e7f1158c\",\"zh_blogs_20191112_index.md\":\"20a903ef\",\"zh_blogs_20210223_index.md\":\"a04bbf06\",\"zh_blogs_20200616_index.md\":\"1909c34c\",\"zh_blogs_20210315_index.md\":\"13799d08\",\"zh_blogs_20210412_index.md\":\"cb1d48be\",\"zh_blogs_20210506_index.md\":\"9a4cc383\",\"zh_blogs_20210430_index.md\":\"7d887266\",\"zh_blogs_20210312_index.md\":\"a97c91e4\",\"zh_blogs_20210409_index.md\":\"3374f5af\",\"zh_blogs_20210329_index.md\":\"48cb84e7\",\"zh_blogs_20200816_index.md\":\"f570af2a\",\"zh_blogs_20191102_index.md\":\"e1722464\",\"zh_blogs_20191103_index.md\":\"9b710856\",\"zh_blogs_20210706_index.md\":\"e46538a1\",\"zh_blogs_20210627_index.md\":\"1767f8a9\",\"zh_blogs_20210822_index.md\":\"6aba4591\",\"zh_blogs_20230101_index.md\":\"e779c786\",\"zh_blogs_20230125_index.md\":\"0e4ab5d9\",\"zh_blogs_20230126_index.md\":\"961f0979\",\"zh_blogs_20221228_index.md\":\"9dc40de8\",\"zh_blogs_20240513_index.md\":\"5054ded0\",\"zh_blogs_20240519_index.md\":\"917234d5\",\"zh_blogs_20240622_index.md\":\"4921f51d\",\"zh_blogs_20220316_index.md\":\"09c75bb7\",\"zh_blogs_20221024_index.md\":\"8ebba006\",\"zh_blogs_20220611_index.md\":\"48a2162f\",\"zh_blogs_20220105_index.md\":\"057ef58c\",\"zh_blogs_20211210_index.md\":\"5cf5ec3b\",\"zh_blogs_20211130_index.md\":\"e06fc018\",\"zh_blogs_20210801_index.md\":\"640475cd\",\"zh_blogs_20240215_index.md\":\"29b27448\",\"zh_blogs_20220101_index.md\":\"28fca584\",\"zh_blogs_20211120_index.md\":\"8e740225\",\"zh_blogs_index.md\":\"284bf08e\",\"zh_blogs_20230121_index.md\":\"1e80c99d\",\"zh_blogs_20210715_index.md\":\"16ce33cc\",\"zh_blogs_20220224_index.md\":\"cdd187f4\",\"zh_blogs_20211002_index.md\":\"c2dacf15\",\"zh_blogs_20230201_index.md\":\"5a07f4b5\",\"zh_blogs_20240128_index.md\":\"9236e79c\",\"zh_blogs_20230601_index.md\":\"cbd6f55d\",\"zh_blogs_20230322_index.md\":\"8ba4df8b\",\"zh_blogs_20240413_index.md\":\"6cfc1faa\",\"zh_blogs_20240626_index.md\":\"6d490338\",\"zh_blogs_20240423_index.md\":\"e39dc142\",\"zh_blogs_20210728_index.md\":\"e67450f5\",\"zh_blogs_20240427_index.md\":\"92f8531f\",\"zh_blogs_20240620_index.md\":\"cadc4632\",\"zh_blogs_20240526_index.md\":\"5cc8945c\",\"zh_blogs_20221108_index.md\":\"e5b7be76\",\"zh_blogs_20240924_index.md\":\"c16775d2\",\"zh_blogs_20241008_index.md\":\"cd84a035\",\"zh_blogs_20240916_index.md\":\"34a833d6\",\"zh_blogs_20240909_index.md\":\"9e9ac428\",\"zh_index.md\":\"bd0115db\",\"zh_blogs_tags_index.md\":\"08460bbb\",\"zh_blogs_20240220_index.md\":\"6f23a2ab\",\"zh_blogs_20241020_index.md\":\"69fa1bf7\",\"zh_blogs_20230201_repost.md\":\"16684978\",\"zh_blogs_20240623_index.md\":\"02de25e1\",\"zh_blogs_20230209_index.md\":\"d6571f6a\",\"zh_blogs_20240518_index.md\":\"cd515693\"}")</script>
    <script type="module" async src="/assets/app.0f5a0ae1.js"></script>
    
  </body>
</html>